{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import preprocessing1\n",
    "\n",
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "import xgboost as xgb\n",
    "import itertools\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "## import\n",
    "df_train = pd.read_csv('./raw_data/train.csv')\n",
    "df_test = pd.read_csv('./raw_data/test.csv')\n",
    "\n",
    "# test dict\n",
    "# params_dict = {\n",
    "#     'max_depth': [10],\n",
    "#     'n_estimators': [1000],\n",
    "#     'eta': [0.1],\n",
    "#     'gamma':[0.5],\n",
    "#     'subsample': [0.95],\n",
    "#     'colsample_bytree': [0.8],\n",
    "#     'min_child_weight':[3],\n",
    "#     'reg_lambda': [0.01]\n",
    "# }\n",
    "\n",
    "params_dict = {\n",
    "    'max_depth': [8,10,12,15],\n",
    "    'n_estimators': [800, 1000],\n",
    "    'eta': [0.01, 0.1, 0.3],\n",
    "    'gamma':[0.1, 0.3, 0.5, 1],\n",
    "    'subsample': [0.7, 0.8, 0.9, 0.95],\n",
    "    'colsample_bytree': [0.8, 0.9, 1],\n",
    "    'min_child_weight':[1, 3, 5],\n",
    "    'reg_lambda': [0.01, 0.1, 1],\n",
    "    'max_delta_step': [1,2,3,5,10]}\n",
    "\n",
    "\n",
    "best_score = 0\n",
    "best_params = {}\n",
    "best_model = None\n",
    "\n",
    "kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "for combination in itertools.product(*params_dict.values()):\n",
    "    params = dict(zip(params_dict.keys(), combination))\n",
    "\n",
    "    model = xgb.XGBClassifier(\n",
    "        tree_method='auto',\n",
    "        enable_categorical=True,\n",
    "        objective='multi:prob',\n",
    "        eval_metric='mlogloss',\n",
    "        max_depth=params['max_depth'],\n",
    "        n_estimators=params['n_estimators'],\n",
    "        eta=params['eta'],\n",
    "        gamma=params['gamma'],\n",
    "        subsample=params['subsample'],\n",
    "        colsample_bytree=params['colsample_bytree'],\n",
    "        min_child_weight=params['min_child_weight'],\n",
    "        reg_lambda=params['reg_lambda'])\n",
    "\n",
    "    for fold, (train_index, valid_index) in enumerate(kf.split(df_train), 0):\n",
    "        acc_val = []\n",
    "\n",
    "        train_set, valid_set = df_train.iloc[train_index], df_train.iloc[valid_index]\n",
    "\n",
    "        ## clean\n",
    "        train_clean, median_dict, bound_dict, median_neigh, median_prope= preprocessing1.train_clean_1_(train_set) \n",
    "        val_clean = preprocessing1.test_clean_1_(valid_set, median_dict, bound_dict, \n",
    "                                                    median_neigh, median_prope, test = False)\n",
    "        X_train, y_train = (train_clean.drop('price', axis=1)).values, (train_clean['price']).values\n",
    "        X_valid, y_valid = (val_clean.drop('price', axis=1)).values, (val_clean['price']).values\n",
    "\n",
    "        ## fit model adn evaluate\n",
    "        model.fit(X_train, y_train, \n",
    "                    early_stopping_rounds=10, eval_set=[(X_valid, y_valid)], verbose=False)\n",
    "        y_val_pred = model.predict(X_valid)\n",
    "        acc_val.append(balanced_accuracy_score(y_valid, y_val_pred))\n",
    "\n",
    "    # Update \n",
    "    mean_acc = np.mean(acc_val)\n",
    "    print('Accuracy: \\n  ', mean_acc, '\\nParams: \\n  ', params)\n",
    "    if mean_acc > best_score:\n",
    "        best_score = mean_acc\n",
    "        best_params = params\n",
    "\n",
    "print(\"Best score:\", best_score)\n",
    "print(\"Best parameters:\", best_params)\n",
    "\n",
    "\n",
    "## test output\n",
    "train_clean, median_dict, bound_dict, median_neigh, median_prope= preprocessing1.train_clean_1_(df_train)\n",
    "test_clean = preprocessing1.test_clean_1_(df_test, median_dict, bound_dict, \n",
    "                                            median_neigh, median_prope, test = True)\n",
    "X_train, y_train = (train_clean.drop('price', axis=1)).values, (train_clean['price']).values\n",
    "X_test = test_clean.values\n",
    "\n",
    "best_model = xgb.XGBClassifier(\n",
    "    tree_method='auto',\n",
    "    enable_categorical=True,\n",
    "    objective='multi:softprob',\n",
    "    eval_metric='mlogloss',\n",
    "    **best_params  \n",
    ")\n",
    "\n",
    "best_model.fit(X_train, y_train, verbose=False)\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "df_predictions = pd.DataFrame({'id': range(len(y_pred)) , 'Price': y_pred})\n",
    "df_predictions.to_csv('submission1.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "274508df9cde7ecc2f982e5f4c4908670322f74137a8243468b9a800234371ff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
