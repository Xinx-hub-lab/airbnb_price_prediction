{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: \n",
      "   0.5615195341523141 \n",
      "Params: \n",
      "   {'max_depth': 20, 'n_estimators': 1000, 'min_samples_split': 5, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'class_weight': 'balanced'}\n",
      "Best score: 0.5615195341523141\n",
      "Best parameters: {'max_depth': 20, 'n_estimators': 1000, 'min_samples_split': 5, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'class_weight': 'balanced'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import preprocessing2\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "# import xgboost as xgb\n",
    "import itertools\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "## import\n",
    "df_train = pd.read_csv('./raw_data/train.csv')\n",
    "df_test = pd.read_csv('./raw_data/test.csv')\n",
    "\n",
    "\n",
    "# params_dict = {\n",
    "#     'max_depth': [10, 15, 20],\n",
    "#     'n_estimators': [500, 1000],\n",
    "#     'min_samples_split': [2,5,10],\n",
    "#     'min_samples_leaf': [1,2,4,6],\n",
    "#     'max_features': ['sqrt', 'log2', 0.5],\n",
    "#     'class_weight': ['balanced', 'balanced_subsample']}\n",
    "\n",
    "params_dict = {\n",
    "    'max_depth': [20],\n",
    "    'n_estimators': [1000],\n",
    "    'min_samples_split': [5],\n",
    "    'min_samples_leaf': [6],\n",
    "    'max_features': ['sqrt'],\n",
    "    'class_weight': ['balanced']}\n",
    "\n",
    "best_score = 0\n",
    "best_params = {}\n",
    "best_model = None\n",
    "\n",
    "kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "for combination in itertools.product(*params_dict.values()):\n",
    "    params = dict(zip(params_dict.keys(), combination))\n",
    "\n",
    "    model = RandomForestClassifier(\n",
    "        max_depth=params['max_depth'],\n",
    "        n_estimators=params['n_estimators'],\n",
    "        min_samples_split=params['min_samples_split'],\n",
    "        min_samples_leaf=params['min_samples_leaf'],\n",
    "        max_features=params['max_features'],\n",
    "        class_weight=params['class_weight'])\n",
    "\n",
    "    for fold, (train_index, valid_index) in enumerate(kf.split(df_train), 0):\n",
    "        acc_val = []\n",
    "\n",
    "        train_set, valid_set = df_train.iloc[train_index], df_train.iloc[valid_index]\n",
    "\n",
    "        ## clean\n",
    "        train_clean, median_dict, bound_dict, median_neigh, median_prope, glob_med_neigh, glob_med_prope= preprocessing2.train_clean_2_(train_set) \n",
    "        val_clean = preprocessing2.test_clean_2_(valid_set, median_dict, bound_dict, \n",
    "                                                    median_neigh, median_prope, glob_med_neigh, glob_med_prope, test = False)\n",
    "        X_train, y_train = (train_clean.drop('price', axis=1)).values, (train_clean['price']).values\n",
    "        X_valid, y_valid = (val_clean.drop('price', axis=1)).values, (val_clean['price']).values\n",
    "\n",
    "        ## fit model adn evaluate\n",
    "        model.fit(X_train, y_train)\n",
    "        y_val_pred = model.predict(X_valid)\n",
    "        acc_val.append(balanced_accuracy_score(y_valid, y_val_pred))\n",
    "\n",
    "    # Update \n",
    "    mean_acc = np.mean(acc_val)\n",
    "    print('Accuracy: \\n  ', mean_acc, '\\nParams: \\n  ', params)\n",
    "    if mean_acc > best_score:\n",
    "        best_score = mean_acc\n",
    "        best_params = params\n",
    "\n",
    "print(\"Best score:\", best_score)\n",
    "print(\"Best parameters:\", best_params)\n",
    "\n",
    "\n",
    "## test output\n",
    "train_clean, median_dict, bound_dict, median_neigh, median_prope, glob_med_neigh, glob_med_prope= preprocessing2.train_clean_2_(df_train)\n",
    "test_clean = preprocessing2.test_clean_2_(df_test, median_dict, bound_dict, \n",
    "                                            median_neigh, median_prope, glob_med_neigh, glob_med_prope, test = True)\n",
    "X_train, y_train = (train_clean.drop('price', axis=1)).values, (train_clean['price']).values\n",
    "X_test = test_clean.values\n",
    "\n",
    "best_model = RandomForestClassifier(\n",
    "    **best_params  \n",
    ")\n",
    "\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "df_predictions = pd.DataFrame({'id': range(len(y_pred)) , 'Price': y_pred})\n",
    "df_predictions.to_csv('submission2.csv', index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: \n",
      "   0.4913496143761364 \n",
      "Params: \n",
      "   {'max_depth': 10, 'n_estimators': 1000, 'eta': 0.01, 'gamma': 0.01, 'subsample': 0.6, 'colsample_bytree': 0.8, 'min_child_weight': 1, 'reg_lambda': 0.01, 'max_delta_step': 7}\n",
      "Best score: 0.4913496143761364\n",
      "Best parameters: {'max_depth': 10, 'n_estimators': 1000, 'eta': 0.01, 'gamma': 0.01, 'subsample': 0.6, 'colsample_bytree': 0.8, 'min_child_weight': 1, 'reg_lambda': 0.01, 'max_delta_step': 7}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import preprocessing2\n",
    "\n",
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "import xgboost as xgb\n",
    "import itertools\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "## import\n",
    "df_train = pd.read_csv('./raw_data/train.csv')\n",
    "df_test = pd.read_csv('./raw_data/test.csv')\n",
    "\n",
    "# test dict\n",
    "params_dict = {\n",
    "    'max_depth': [10],\n",
    "    'n_estimators': [1000],\n",
    "    'eta': [0.01],\n",
    "    'gamma':[0.01],\n",
    "    'subsample': [0.6],\n",
    "    'colsample_bytree': [0.8],\n",
    "    'min_child_weight':[1],\n",
    "    'reg_lambda': [0.01],\n",
    "    'max_delta_step': [7]\n",
    "}\n",
    "\n",
    "# params_dict = {\n",
    "#     'max_depth': [8,10,12,15],\n",
    "#     'n_estimators': [800, 1000],\n",
    "#     'eta': [0.01, 0.1, 0.3],\n",
    "#     'gamma':[0.1, 0.3, 0.5, 1],\n",
    "#     'subsample': [0.7, 0.8, 0.9, 0.95],\n",
    "#     'colsample_bytree': [0.8, 0.9, 1],\n",
    "#     'min_child_weight':[1, 3, 5],\n",
    "#     'reg_lambda': [0.01, 0.1, 1],\n",
    "#     'max_delta_step': [1,2,3,5,10]}\n",
    "\n",
    "\n",
    "best_score = 0\n",
    "best_params = {}\n",
    "best_model = None\n",
    "\n",
    "kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "for combination in itertools.product(*params_dict.values()):\n",
    "    params = dict(zip(params_dict.keys(), combination))\n",
    "\n",
    "    model = xgb.XGBClassifier(\n",
    "        tree_method='auto',\n",
    "        enable_categorical=True,\n",
    "        objective='multi:prob',\n",
    "        eval_metric='mlogloss',\n",
    "        max_depth=params['max_depth'],\n",
    "        n_estimators=params['n_estimators'],\n",
    "        eta=params['eta'],\n",
    "        gamma=params['gamma'],\n",
    "        subsample=params['subsample'],\n",
    "        colsample_bytree=params['colsample_bytree'],\n",
    "        min_child_weight=params['min_child_weight'],\n",
    "        reg_lambda=params['reg_lambda'])\n",
    "\n",
    "    for fold, (train_index, valid_index) in enumerate(kf.split(df_train), 0):\n",
    "        acc_val = []\n",
    "\n",
    "        train_set, valid_set = df_train.iloc[train_index], df_train.iloc[valid_index]\n",
    "\n",
    "        ## clean\n",
    "        train_clean, median_dict, bound_dict, median_neigh, median_prope, glob_med_neigh, glob_med_prope= preprocessing2.train_clean_2_(train_set) \n",
    "        val_clean = preprocessing2.test_clean_2_(valid_set, median_dict, bound_dict, \n",
    "                                                    median_neigh, median_prope, glob_med_neigh, glob_med_prope, test = False)\n",
    "        X_train, y_train = (train_clean.drop('price', axis=1)).values, (train_clean['price']).values\n",
    "        X_valid, y_valid = (val_clean.drop('price', axis=1)).values, (val_clean['price']).values\n",
    "\n",
    "        ## fit model adn evaluate\n",
    "        model.fit(X_train, y_train, \n",
    "                    early_stopping_rounds=10, eval_set=[(X_valid, y_valid)], verbose=False)\n",
    "        y_val_pred = model.predict(X_valid)\n",
    "        acc_val.append(balanced_accuracy_score(y_valid, y_val_pred))\n",
    "\n",
    "    # Update \n",
    "    mean_acc = np.mean(acc_val)\n",
    "    print('Accuracy: \\n  ', mean_acc, '\\nParams: \\n  ', params)\n",
    "    if mean_acc > best_score:\n",
    "        best_score = mean_acc\n",
    "        best_params = params\n",
    "\n",
    "print(\"Best score:\", best_score)\n",
    "print(\"Best parameters:\", best_params)\n",
    "\n",
    "\n",
    "## test output\n",
    "train_clean, median_dict, bound_dict, median_neigh, median_prope, glob_med_neigh, glob_med_prope= preprocessing2.train_clean_2_(df_train)\n",
    "test_clean = preprocessing2.test_clean_2_(df_test, median_dict, bound_dict, \n",
    "                                            median_neigh, median_prope, glob_med_neigh, glob_med_prope, test = True)\n",
    "X_train, y_train = (train_clean.drop('price', axis=1)).values, (train_clean['price']).values\n",
    "X_test = test_clean.values\n",
    "\n",
    "best_model = xgb.XGBClassifier(\n",
    "    tree_method='auto',\n",
    "    enable_categorical=True,\n",
    "    objective='multi:softmax',\n",
    "    eval_metric='mlogloss',\n",
    "    **best_params  \n",
    ")\n",
    "\n",
    "best_model.fit(X_train, y_train, verbose=False)\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "df_predictions = pd.DataFrame({'id': range(len(y_pred)) , 'Price': y_pred})\n",
    "df_predictions.to_csv('submission1.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy: \n",
    "#    0.5671880745888057 \n",
    "# Params: \n",
    "#    {'max_depth': 10, 'n_estimators': 1000, 'eta': 0.1, 'gamma': 0.5, 'subsample': 0.95, 'colsample_bytree': 0.8, 'min_child_weight': 3, 'reg_lambda': 0.01}\n",
    "\n",
    "# Accuracy: \n",
    "#    0.5671024113732074 \n",
    "# Params: \n",
    "#    {'max_depth': 9, 'n_estimators': 1200, 'eta': 0.1, 'gamma': 0.5, 'subsample': 0.95, 'colsample_bytree': 0.8, 'min_child_weight': 3, 'reg_lambda': 0.01}\n",
    "\n",
    "# Accuracy: \n",
    "#    0.5421702331508867 \n",
    "# Params: \n",
    "#    {'max_depth': 10, 'n_estimators': 1000, 'eta': 0.3, 'gamma': 0.5, 'subsample': 0.7, 'colsample_bytree': 0.8, 'min_child_weight': 3, 'reg_lambda': 0.01}\n",
    "\n",
    "# Accuracy: \n",
    "#    0.5498288445186382 \n",
    "# Params: \n",
    "#    {'max_depth': 10, 'n_estimators': 1000, 'eta': 0.3, 'gamma': 0.5, 'subsample': 0.8, 'colsample_bytree': 0.8, 'min_child_weight': 3, 'reg_lambda': 0.01}\n",
    "\n",
    "# Accuracy: \n",
    "#    0.5594133712685273 \n",
    "# Params: \n",
    "#    {'max_depth': 10, 'n_estimators': 1000, 'eta': 0.1, 'gamma': 0.5, 'subsample': 0.8, 'colsample_bytree': 0.8, 'min_child_weight': 3, 'reg_lambda': 0.01, 'max_delta_step': 5}\n",
    "\n",
    "# Accuracy: \n",
    "#    0.5715560498031736 \n",
    "# Params: \n",
    "#    {'max_depth': 10, 'n_estimators': 1000, 'eta': 0.01, 'gamma': 0.5, 'subsample': 0.8, 'colsample_bytree': 0.8, 'min_child_weight': 3, 'reg_lambda': 0.01, 'max_delta_step': 3}\n",
    "## eta is boosting acc\n",
    "\n",
    "# Accuracy: \n",
    "#    0.571546728960379 \n",
    "# Params: \n",
    "#    {'max_depth': 10, 'n_estimators': 1000, 'eta': 0.01, 'gamma': 0.5, 'subsample': 0.8, 'colsample_bytree': 0.8, 'min_child_weight': 1, 'reg_lambda': 0.01, 'max_delta_step': 3}\n",
    "\n",
    "# Accuracy: \n",
    "#    0.566775071158093 \n",
    "# Params: \n",
    "#    {'max_depth': 10, 'n_estimators': 1000, 'eta': 0.01, 'gamma': 0.7, 'subsample': 0.8, 'colsample_bytree': 0.8, 'min_child_weight': 1, 'reg_lambda': 0.01, 'max_delta_step': 7}\n",
    "\n",
    "# Accuracy: \n",
    "#    0.5730900839972636 \n",
    "# Params: \n",
    "#    {'max_depth': 10, 'n_estimators': 1000, 'eta': 0.01, 'gamma': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'min_child_weight': 1, 'reg_lambda': 0.01, 'max_delta_step': 7}\n",
    "\n",
    "# Accuracy: \n",
    "#    0.57403912919536   __0.56127\n",
    "# Params: \n",
    "#    {'max_depth': 10, 'n_estimators': 1000, 'eta': 0.01, 'gamma': 0.1, 'subsample': 0.5, 'colsample_bytree': 0.8, 'min_child_weight': 1, 'reg_lambda': 0.01, 'max_delta_step': 7}\n",
    "\n",
    "# Accuracy: \n",
    "#    0.5748324286382628 \n",
    "# Params: \n",
    "#    {'max_depth': 10, 'n_estimators': 1000, 'eta': 0.01, 'gamma': 0.1, 'subsample': 0.6, 'colsample_bytree': 0.8, 'min_child_weight': 1, 'reg_lambda': 0.01, 'max_delta_step': 7}\n",
    "\n",
    "# Accuracy: \n",
    "#    0.5729162888383669 \n",
    "# Params: \n",
    "#    {'max_depth': 10, 'n_estimators': 1000, 'eta': 0.01, 'gamma': 0.1, 'subsample': 0.7, 'colsample_bytree': 0.8, 'min_child_weight': 1, 'reg_lambda': 0.01, 'max_delta_step': 7}\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## cross validation\n",
    "# model = xgb.XGBClassifier(n_estimators=1000, \n",
    "#                           max_depth=7, \n",
    "#                           eta=0.1, \n",
    "#                           subsample=0.7, \n",
    "#                           colsample_bytree=0.8, \n",
    "#                           enable_categorical=True,\n",
    "#                           objective = 'multi:softmax')\n",
    "# X, y = train_clean.iloc[:, :-1].to_numpy(), train_clean.iloc[:, -1].to_numpy()\n",
    "\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# model.fit(X_train, y_train)\n",
    "# y_pred = np.round(model.predict(X_val))\n",
    "# y_pred[y_pred == 6.0] = 5.0\n",
    "# y_pred[y_pred == -1.0] = 0\n",
    "# accuracy = accuracy_score(y_val, y_pred)\n",
    "# print(\"Accuracy:\", accuracy)\n",
    "\n",
    "\n",
    "# ## test output\n",
    "# X_test = test_clean.to_numpy()\n",
    "# y_pred = model.predict(X_test)\n",
    "\n",
    "# df_predictions = pd.DataFrame({'id': range(len(y_pred)) , 'Price': y_pred})\n",
    "# df_predictions.to_csv('submission.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Accuracy: 0.5272020725388601\n",
    "## Accuracy: 0.5310880829015544 -- bound [0,5]\n",
    "## Accuracy: 0.5310880829015544 -- lower bound = 0\n",
    "\n",
    "\n",
    "## Accuracy: 0.5660621761658031 ---classifier\n",
    "## Accuracy: 0.5660621761658031 ---classifier  15.7s\n",
    "## Accuracy: 0.5537564766839378\n",
    "##              0.5589378238341969\n",
    "##              0.5621761658031088\n",
    "\n",
    "\n",
    "# 'calculated_host_listings_count_entire_homes', 'calculated_host_listings_count', 'host_total_listings_count',\n",
    "#                               'minimum_nights', 'maximum_minimum_nights', 'minimum_maximum_nights',\n",
    "#                               'minimum_nights_avg_ntm','maximum_nights', \n",
    "#                               'availability_60', 'availability_90', 'availability_365',   0.5550518134715026, 0.5712435233160622\n",
    "#                               'number_of_reviews_l30d', 'number_of_reviews',   0.5718911917098446\n",
    "#                               'bedrooms', 'beds',   0.5621761658031088\n",
    "#                               'host_has_profile_pic'  0.5615284974093264\n",
    "\n",
    "\n",
    "# 'number_of_reviews_l30d', 'number_of_reviews'\n",
    "\n",
    "## Accuracy: 0.577    target encode\n",
    "## Accuracy: 0.5841968911917098   --label\n",
    "## Accuracy: 0.5841968911917098   -- category\n",
    "## no kink outlier --> drop to 0.56\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test dict\n",
    "#     params_dict = {\n",
    "#         'max_depth': [10],\n",
    "#         'n_estimators': [1000],\n",
    "#         'eta': [0.1],\n",
    "#         'gamma':[0.5],\n",
    "#         'subsample': [0.95],\n",
    "#         'colsample_bytree': [0.8],\n",
    "#         'min_child_weight':[3],\n",
    "#         'reg_lambda': [0.01]\n",
    "#     }\n",
    "\n",
    "## Accuracy:  10\n",
    "#    0.5675342354275558   0.55489\n",
    "\n",
    "# 4m  ## 0.5673575129533679, 0.55479\n",
    "# Best parameters: {'max_depth': 7, 'n_estimators': 1000, 'eta': 0.1, 'gamma': 0.1, \n",
    "# 'subsample': 0.7, 'colsample_bytree': 0.8, 'min_child_weight': 3, 'reg_lambda': 0.01}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#host_id cannot be added:0.5675342354275558 - 0.5601632618442313\n",
    "## target 0.5283550346491853 -- 0.5404111858372997 -- 0.5675342354275558\n",
    "\n",
    "\n",
    "\n",
    "# Accuracy: \n",
    "#    0.5721689470355151 \n",
    "# Params: \n",
    "#    {'max_depth': 10, 'n_estimators': 1000, 'eta': 0.01, 'gamma': 0.5, 'subsample': 0.95, 'colsample_bytree': 0.8, 'min_child_weight': 3, 'reg_lambda': 0.1, 'max_delta_step': 5}\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "274508df9cde7ecc2f982e5f4c4908670322f74137a8243468b9a800234371ff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
